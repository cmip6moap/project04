{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import nc_time_axis\n",
    "import cftime\n",
    "\n",
    "from palettable.cmocean.diverging import Balance_10\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy_to_cftime(dy):\n",
    "    '''\n",
    "    A horrible hacky way to try and convert decimal years (yyyy.yyy)\n",
    "    to a datetime that will cope with dates beyond 2622 (pandas limitation\n",
    "    of 64-bit integer for their date range), in this case cftime.\n",
    "    \n",
    "    Currently assuming a 365-day calendar, as we are resampling annually,\n",
    "    only the year is important.\n",
    "    \n",
    "    If anyone can improve on this, please do!\n",
    "    '''\n",
    "    \n",
    "    # Split into year and decimal part of year\n",
    "    dec, year = math.modf(dy)\n",
    "\n",
    "    # Create a numpy datetime for the year\n",
    "    dt = datetime(int(year), 1, 1)\n",
    "\n",
    "    # Convert decimal year to days - this is assuming 365 day calendar\n",
    "    days = dec * 365\n",
    "    \n",
    "    # Use timedelta to add days to year\n",
    "    td = timedelta(days=days)\n",
    "    dt = dt + td\n",
    "\n",
    "    # Create cftime datetime\n",
    "    cf_dt = cftime.datetime(dt.year, dt.month, dt.day)\n",
    "    \n",
    "    return cf_dt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamfunction(ds):\n",
    "    '''\n",
    "    From the Dataset containing the transport in Sv/10m, \n",
    "    calculate the streamfunction as the integral sum from the\n",
    "    surface downwards, take the annual and time series means,\n",
    "    and the maximum streamfunction for each time and latitude.\n",
    "    '''\n",
    "    \n",
    "    # Convert time coordinates from decimal year to cf datetime, to allow resampling by\n",
    "    # year and also cope with years beyond 2262 (pandas datetime cannot handle these).\n",
    "    dt = []\n",
    "\n",
    "    for t in ds.time.values:\n",
    "        dt.append(dy_to_cftime(t))\n",
    "\n",
    "    dt = np.array(dt)\n",
    "    \n",
    "    # Add the new datetime to the Dataset and swap 'time' (decimal year) and 'datetime' (cftime)\n",
    "    # as dimensions\n",
    "    ds['datetime'] = (('time'), dt)\n",
    "    transport_ds = ds.swap_dims({'time': 'datetime'})\n",
    "    \n",
    "    # Calculate streamfunction as cumulative integration from the surface downward\n",
    "    strf_ds = transport_ds.cumsum(dim='depth')\n",
    "    \n",
    "    # Calculate annual mean by resampling by year\n",
    "    avg_strf_ds = strf_ds.resample(datetime='Y').mean()\n",
    "    \n",
    "    # Take the historical (timeseries) mean to plot the overturning\n",
    "    hist_strf_ds = strf_ds.mean(dim='datetime')\n",
    "    \n",
    "    # Get maximum of annual streamfunction as the AMOC index\n",
    "    max_strf_ds = avg_strf_ds.max(dim='depth')\n",
    "    \n",
    "    return hist_strf_ds, max_strf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overturning(hist_ds, model):\n",
    "    '''\n",
    "    Plot the historical mean overturning streamfunction.\n",
    "    '''\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(hist_ds.latitude, hist_ds.depth, hist_ds.transport.transpose(), levels=13, cmap=Balance_10.mpl_colormap)\n",
    "    plt.title('Historical mean streamfunction for ' + model)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('Latitude')\n",
    "    plt.ylabel('Depth')\n",
    "    plt.savefig('/home/users/elw2u16/hackathon/project04/results/amoc_streamfunction/' + model + '.png', format='png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amoc(max_ds, model, lat):\n",
    "    '''\n",
    "    Plot the maximum overturning streamfunction at a given latitude\n",
    "    '''\n",
    "    \n",
    "    # Extract data at given latitude\n",
    "    lat_max_ds = max_ds.sel(latitude=lat)\n",
    "    \n",
    "    # Convert cftime to plottable type\n",
    "    c_d_time = [nc_time_axis.CalendarDateTime(item, \"365_day\") for item in lat_max_ds.datetime.values]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(c_d_time, lat_max_ds.transport)\n",
    "    plt.ylabel('AMOC [Sv]')\n",
    "    plt.xlim([c_d_time[0], c_d_time[-1]])\n",
    "    plt.title('AMOC strength at latitude ' + str(lat) + 'N for ' + model)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/users/elw2u16/hackathon/project04/results/amoc_index_timeseries/' + model + '_' + str(lat) + '.png', format='png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_amoc_index(ds, lat, mip, model_name):\n",
    "    '''\n",
    "    Create a netCDF file for the maximum overturning streamfunction\n",
    "    as an AMOC index for the given model/scenario/forcing with\n",
    "    appropriate metadata.\n",
    "    '''\n",
    "    \n",
    "    # Extract data at given latitude\n",
    "    lat_ds = ds.sel(latitude=lat)\n",
    "    \n",
    "    # Save to local directory as cannot save to group workspace from notebook\n",
    "    home_dir = str(Path.home())\n",
    "    results_dir = home_dir + '/hackathon/project04/data/processed_data/CMIP6/amoc/'\n",
    "    \n",
    "    # Get scenario from model name to save in correct directory\n",
    "    model, scenario, forcing = model_name.split('_')\n",
    "    \n",
    "    # Get today's date as formatted string\n",
    "    today = np.datetime64('now')\n",
    "    ts = pd.to_datetime(str(today))\n",
    "    \n",
    "    # Add metadata\n",
    "    lat_ds.attrs['short_desc'] = 'AMOC index (annual mean max streamfunction)'\n",
    "    lat_ds.attrs['latitude'] = str(lat)\n",
    "    lat_ds.attrs['model'] = model\n",
    "    lat_ds.attrs['scenario'] = scenario\n",
    "    lat_ds.attrs['forcing'] = forcing\n",
    "    lat_ds.attrs['date_created'] = ts.strftime('%d %b %Y')\n",
    "    \n",
    "    # Save netcdf\n",
    "    lat_ds.to_netcdf(results_dir + mip + '/' + scenario + '/' + model_name + '-1ym-amoc-index_' + str(lat) + '.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_10yr_mean_amoc_index(ds, lat, mip, model_name):\n",
    "    '''\n",
    "    Create 10-year rolling mean of AMOC index.\n",
    "    '''\n",
    "    \n",
    "    # Extract data at given latitude\n",
    "    lat_ds = ds.sel(latitude=lat)\n",
    "    \n",
    "    # Take rolling 10-year mean\n",
    "    mean_ds = lat_ds.rolling(datetime=10).mean()\n",
    "    \n",
    "    # Save to local directory as cannot save to group workspace from notebook\n",
    "    home_dir = str(Path.home())\n",
    "    results_dir = home_dir + '/hackathon/project04/data/processed_data/CMIP6/amoc/'\n",
    "    \n",
    "    # Get scenario from model name to save in correct directory\n",
    "    model, scenario, forcing = model_name.split('_')\n",
    "    \n",
    "    # Get today's date as formatted string\n",
    "    today = np.datetime64('now')\n",
    "    ts = pd.to_datetime(str(today))\n",
    "    \n",
    "    # Add metadata\n",
    "    mean_ds.attrs['short_desc'] = 'AMOC index (10-year rolling mean max streamfunction)'\n",
    "    mean_ds.attrs['latitude'] = str(lat)\n",
    "    mean_ds.attrs['model'] = model\n",
    "    mean_ds.attrs['scenario'] = scenario\n",
    "    mean_ds.attrs['forcing'] = forcing\n",
    "    mean_ds.attrs['date_created'] = ts.strftime('%d %b %Y')\n",
    "    \n",
    "    # Save netCDF \n",
    "    mean_ds.to_netcdf(results_dir + mip + '/' + scenario + '/' + model_name + '-10ym-amoc-index_' + str(lat) + '.nc')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_group(scenario_group, mip, scenario, lat):\n",
    "    '''\n",
    "    Do all the processing required for each model scenario.\n",
    "    \n",
    "    Get the AMOC index (maximum streamfunction) and the historical mean streamfunction,\n",
    "    save the AMOC index and its 10-year rolling mean, and\n",
    "    plot the AMOC index and the overturning streamfunction.\n",
    "    '''\n",
    "    \n",
    "    data_dir = '/gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/'\n",
    "    group_dir = data_dir + mip + '/' + scenario + '/'\n",
    "    \n",
    "    for i in np.arange(scenario_group.scenario.size):\n",
    "    \n",
    "        model = scenario_group.iloc[i]\n",
    "\n",
    "        # Load transport data\n",
    "        model_name = model.model + '_' + model.scenario + '_' + model.forcing\n",
    "        print('Processing', group_dir + model_name + '_gn_amoc10m.nc')\n",
    "        transport_ds = xr.open_dataset(group_dir + model.model + '_' + model.scenario + '_' + model.forcing + '_gn_amoc10m.nc', use_cftime=True)\n",
    "        \n",
    "        # Get the maximum and historical mean streamfunction\n",
    "        hist_strf_ds, max_strf_ds = streamfunction(transport_ds)\n",
    "        \n",
    "        # Save the maximum streamfunction as AMOC index\n",
    "        save_amoc_index(max_strf_ds, lat, mip, model_name)\n",
    "        \n",
    "        # Save 10-year rolling mean of AMOC index\n",
    "        save_10yr_mean_amoc_index(max_strf_ds, lat, mip, model_name)\n",
    "\n",
    "        # Get first part of filename to save figure                                                \n",
    "        plot_amoc(max_strf_ds, model_name, lat) \n",
    "        \n",
    "        # Plot overturning streamfunction\n",
    "        plot_overturning(hist_strf_ds, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get primary AMOC list\n",
    "home_dir = str(Path.home())\n",
    "model_list = home_dir + '/hackathon/project04/working_amoc_list'\n",
    "amoc_models = pd.read_csv(model_list, names=['model', 'scenario', 'forcing'], delimiter=',', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split models by scenario\n",
    "scenario_group = amoc_models.groupby('scenario')\n",
    "\n",
    "ssp126 = scenario_group.get_group('ssp126')\n",
    "ssp245 = scenario_group.get_group('ssp245')\n",
    "ssp585 = scenario_group.get_group('ssp585')\n",
    "historical = scenario_group.get_group('historical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/ACCESS-CM2_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/ACCESS-ESM1-5_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/BCC-CSM2-MR_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/BCC-ESM1_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/CAMS-CSM1-0_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/CESM2_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/CESM2-FV2_historical_r1i1p1f1_gn_amoc10m.nc\n",
      "Processing /gws/pw/j05/cop26_hackathons/bristol/project04/raw_data/CMIP6/amoc/CMIP/historical/CESM2-WACCM_historical_r1i1p1f1_gn_amoc10m.nc\n"
     ]
    }
   ],
   "source": [
    "# Do the processing for each model + scenario for 26.5 N\n",
    "\n",
    "process_group(historical, 'CMIP', 'historical', 26.5)\n",
    "# process_group(ssp126, 'ScenarioMIP', 'ssp126', 26.5)\n",
    "# process_group(ssp245, 'ScenarioMIP', 'ssp245', 26.5)\n",
    "# process_group(ssp585, 'ScenarioMIP', 'ssp585', 26.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmip6",
   "language": "python",
   "name": "cmip6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
